{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"09_mlp_tf.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPSRen8eVejmte/aYu4l+X+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ix5yUb9S5fcl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619437945111,"user_tz":-540,"elapsed":731,"user":{"displayName":"KAEUN LEE","photoUrl":"","userId":"08639815804686491349"}},"outputId":"31840732-6634-4a26-dc46-569cdf075020"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9jnE5Q3n58Kb","executionInfo":{"status":"ok","timestamp":1619437951052,"user_tz":-540,"elapsed":593,"user":{"displayName":"KAEUN LEE","photoUrl":"","userId":"08639815804686491349"}},"outputId":"cc1371da-5add-469d-ff5e-7f07501fcd8f"},"source":["import os\n","os.getcwd()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9gitpa1P6CKC","executionInfo":{"status":"ok","timestamp":1619438010745,"user_tz":-540,"elapsed":13830,"user":{"displayName":"KAEUN LEE","photoUrl":"","userId":"08639815804686491349"}},"outputId":"717d41da-7bdc-443a-9f9f-595faece4949"},"source":["import numpy as np\n","from random import random\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","# array([[0.1, 0.2], [0.2, 0.2]])\n","# array([[0.3], [0.4]])\n","\n","def generate_dataset(num_samples, test_size):\n","    x = np.array([[random()/2 for _ in range(2)] for _ in range(num_samples)])\n","    y = np.array([[i[0] + i[1]] for i in x])\n","    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n","    return x_train, x_test, y_train, y_test\n","\n","if __name__ == \"__main__\":\n","    x_train, x_test, y_train, y_test = generate_dataset(5000, 0.3)\n","    # print(\"x_test: \\n {}\".format(x_test))\n","    # print(\"y_test: \\n {}\".format(y_test))\n","\n","    # build model: 2 -> 5 -> 1\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Dense(5, input_dim=2, activation=\"sigmoid\"),\n","        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","    ])\n","    \n","    # compile model;\n","    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n","    model.compile(optimizer=optimizer, loss=\"MSE\")\n","    \n","    # train model\n","    model.fit(x_train, y_train, epochs=100)\n","    \n","    # evaluate model\n","    print(\"\\nModel evaluation:\")\n","    model.evaluate(x_test, y_test, verbose=1)\n","    \n","    # make predictions\n","    data = np.array([[0.1, 0.2], [0.2, 0.2]])\n","    predictions = model.predict(data)\n","    \n","    print(\"\\nSome predictions:\")\n","    for d, p in zip(data, predictions):\n","        print(\" {} + {} = {}\".format(d[0], d[1], p[0]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0472\n","Epoch 2/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0471\n","Epoch 3/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0446\n","Epoch 4/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0454\n","Epoch 5/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0460\n","Epoch 6/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0442\n","Epoch 7/100\n","110/110 [==============================] - 0s 917us/step - loss: 0.0435\n","Epoch 8/100\n","110/110 [==============================] - 0s 986us/step - loss: 0.0436\n","Epoch 9/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0418\n","Epoch 10/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0424\n","Epoch 11/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0422\n","Epoch 12/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0431\n","Epoch 13/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0427\n","Epoch 14/100\n","110/110 [==============================] - 0s 990us/step - loss: 0.0420\n","Epoch 15/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0424\n","Epoch 16/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0413\n","Epoch 17/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0409\n","Epoch 18/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0397\n","Epoch 19/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0410\n","Epoch 20/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0405\n","Epoch 21/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0404\n","Epoch 22/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0398\n","Epoch 23/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0395\n","Epoch 24/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0406\n","Epoch 25/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0386\n","Epoch 26/100\n","110/110 [==============================] - 0s 991us/step - loss: 0.0395\n","Epoch 27/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0395\n","Epoch 28/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0380\n","Epoch 29/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0370\n","Epoch 30/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0359\n","Epoch 31/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0380\n","Epoch 32/100\n","110/110 [==============================] - 0s 901us/step - loss: 0.0342\n","Epoch 33/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0354\n","Epoch 34/100\n","110/110 [==============================] - 0s 911us/step - loss: 0.0362\n","Epoch 35/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0355\n","Epoch 36/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0347\n","Epoch 37/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0341\n","Epoch 38/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0330\n","Epoch 39/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0316\n","Epoch 40/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0331\n","Epoch 41/100\n","110/110 [==============================] - 0s 965us/step - loss: 0.0308\n","Epoch 42/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0313\n","Epoch 43/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0301\n","Epoch 44/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0289\n","Epoch 45/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0288\n","Epoch 46/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0283\n","Epoch 47/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0273\n","Epoch 48/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0267\n","Epoch 49/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0261\n","Epoch 50/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0257\n","Epoch 51/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0246\n","Epoch 52/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0241\n","Epoch 53/100\n","110/110 [==============================] - 0s 946us/step - loss: 0.0235\n","Epoch 54/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0227\n","Epoch 55/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0223\n","Epoch 56/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0204\n","Epoch 57/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0197\n","Epoch 58/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0192\n","Epoch 59/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0185\n","Epoch 60/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0182\n","Epoch 61/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0166\n","Epoch 62/100\n","110/110 [==============================] - 0s 989us/step - loss: 0.0156\n","Epoch 63/100\n","110/110 [==============================] - 0s 970us/step - loss: 0.0155\n","Epoch 64/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0140\n","Epoch 65/100\n","110/110 [==============================] - 0s 913us/step - loss: 0.0135\n","Epoch 66/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0128\n","Epoch 67/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0118\n","Epoch 68/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0115\n","Epoch 69/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0109\n","Epoch 70/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0101\n","Epoch 71/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0101\n","Epoch 72/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0088\n","Epoch 73/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0086\n","Epoch 74/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0083\n","Epoch 75/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0076\n","Epoch 76/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0071\n","Epoch 77/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0067\n","Epoch 78/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0062\n","Epoch 79/100\n","110/110 [==============================] - 0s 995us/step - loss: 0.0062\n","Epoch 80/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0056\n","Epoch 81/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0052\n","Epoch 82/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0051\n","Epoch 83/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0046\n","Epoch 84/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0044\n","Epoch 85/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0041\n","Epoch 86/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0038\n","Epoch 87/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0036\n","Epoch 88/100\n","110/110 [==============================] - 0s 990us/step - loss: 0.0033\n","Epoch 89/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0031\n","Epoch 90/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0029\n","Epoch 91/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0029\n","Epoch 92/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0025\n","Epoch 93/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0025\n","Epoch 94/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0023\n","Epoch 95/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0021\n","Epoch 96/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0019\n","Epoch 97/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0020\n","Epoch 98/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0018\n","Epoch 99/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0017\n","Epoch 100/100\n","110/110 [==============================] - 0s 984us/step - loss: 0.0016\n","\n","Model evaluation:\n","47/47 [==============================] - 0s 905us/step - loss: 0.0015\n","\n","Some predictions:\n"," 0.1 + 0.2 = 0.3212774991989136\n"," 0.2 + 0.2 = 0.41175296902656555\n"],"name":"stdout"}]}]}