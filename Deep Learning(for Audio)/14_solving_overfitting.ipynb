{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"14_solving_overfitting","provenance":[],"authorship_tag":"ABX9TyNsWTfFQnOXZnvR+7vGlue3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSTQtAuTaSA2","executionInfo":{"status":"ok","timestamp":1621491375169,"user_tz":-540,"elapsed":19466,"user":{"displayName":"KAEUN LEE","photoUrl":"","userId":"08639815804686491349"}},"outputId":"e3f85254-0914-4fa0-edef-ec4fe60f74e9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"daECGm3Nak-u","executionInfo":{"status":"ok","timestamp":1621491377257,"user_tz":-540,"elapsed":632,"user":{"displayName":"KAEUN LEE","photoUrl":"","userId":"08639815804686491349"}},"outputId":"84ae82c6-2a32-4d17-c2ad-36c5ff00b562"},"source":["import os\n","os.getcwd()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"Id288i8rcKV1"},"source":["import json\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow.keras as keras\n","\n","# path to json file that stores MFCCs and genre labels for each porcessed segment\n","DATASET_PATH = \"/content/drive/MyDrive/DL_for_Audio/data/json/data.json\"  \n","\n","def load_data(dataset_path):\n","  \"\"\"Loads training dataset from json file.\n","\n","      :param data_path (str) : path to json file containing data\n","      :return X (ndarray) : Inputs\n","      :return Y (ndarray) : Targets\n","  \"\"\"\n","  \n","  with open(dataset_path, \"r\") as fp:\n","    data = json.load(fp)\n","\n","  # convert lists into numpy arrays\n","  X = np.array(data[\"mfcc\"])          # mfcc, labels 값이 list이므로 -> numpy array로 변경\n","  y = np.array(data[\"labels\"])       \n","\n","  return X, y\n","\n","if __name__ == \"__main__\" :\n","\n","  # load data\n","  X, y = load_data(DATASET_PATH)\n","\n","  # split the data into train and test sets\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n","  \n","  # build the network architecture\n","  model = keras.Sequential([\n","                            \n","      # input layer\n","      keras.layers.Flatten(input_shape=(X.shape[1], X.shape[2])),  # data를 1차원으로 flatten\n","\n","      # 1st hidden(dense) layer\n","      keras.layers.Dense(512, activation=\"relu\"),  \n","\n","      # 2nd hidden layer\n","      keras.layers.Dense(256, activation=\"relu\"),\n","\n","      # 3rd hidden layer\n","      keras.layers.Dense(64, activation=\"relu\"),\n","\n","      # output layer\n","      keras.layers.Dense(10, activation=\"softmax\")\n","  ])\n","\n","  # compile model(network)\n","  optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n","  model.compile(optimizer=optimizer,\n","                loss=\"sparse_categorical_crossentropy\",\n","                metrics=[\"accuracy\"])\n","  \n","  model.summary()\n","\n","  # train model\n","  history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=50)\n","\n","  # p"],"execution_count":null,"outputs":[]}]}